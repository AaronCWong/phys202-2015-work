{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "# Algorithms Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "## Word counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "Write a function `tokenize` that takes a string of English text returns a list of words. It should also remove [stop words](http://en.wikipedia.org/wiki/Stop_words), which are common short words that are often removed before natural language processing. Your function should have the following logic:\n",
    "\n",
    "* Split the string into lines using `splitlines`.\n",
    "* Split each line into a list of words and merge the lists for each line.\n",
    "* Use Python's builtin `filter` function to remove all punctuation.\n",
    "* If `stop_words` is a list, remove all occurences of the words in the list.\n",
    "* If `stop_words` is a space delimeted string of words, split them and remove them.\n",
    "* Remove any remaining empty words.\n",
    "* Make all words lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190\n"
     ]
    }
   ],
   "source": [
    "file = open('mobydick_chapter1.txt')\n",
    "mobydick = file.read()\n",
    "mobydick.splitlines()\n",
    "mobydick.split()\n",
    "print (len(mobydick.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "6b81e3d18c7d985eb0f20f45b5a1e33a",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(s, stop_words=None, punctuation='`~!@#$%^&*()_-+={[}]|\\:;\"<,>.?/}\\t'):\n",
    "    lines = s.splitlines()\n",
    "    i = 0\n",
    "    empty = []\n",
    "    while i < len.lines:\n",
    "        empty.extend(lines[i].split())\n",
    "        i += 1\n",
    "    a = []\n",
    "    b = 0\n",
    "    while b < len(empty):\n",
    "        a.append(''.join([c for c in empty[b] if c not in punctuation]))\n",
    "        b += 1\n",
    "    for g in a:\n",
    "        g.lower()    \n",
    "    c = 0\n",
    "    d = []\n",
    "    while c < len(h):\n",
    "        d.append(''.join([e for e in h[c] if h[c] not in stop_words]))\n",
    "        c+=1\n",
    "    answer = list(filter(None,d))\n",
    "    return answer\n",
    "    \n",
    "    \"\"\"Split a string into a list of words, removing punctuation and stop words.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "51938ebee4d1863467fba80579b46318",
     "grade": true,
     "grade_id": "algorithmsex01a",
     "points": 2
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cb7875c10e3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This, is the way; that things will end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'the'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[1;34m'this'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'way'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'that'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'things'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'will'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m wasteland = \"\"\"\n\u001b[0;32m      3\u001b[0m \u001b[0mAPRIL\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcruellest\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbreeding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mLilacs\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdead\u001b[0m \u001b[0mland\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmixing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMemory\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdesire\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstirring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-034065b48e22>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(s, stop_words, punctuation)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mempty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mempty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'lines'"
     ]
    }
   ],
   "source": [
    "assert tokenize(\"This, is the way; that things will end\", stop_words=['the', 'is']) == \\\n",
    "    ['this', 'way', 'that', 'things', 'will', 'end']\n",
    "wasteland = \"\"\"\n",
    "APRIL is the cruellest month, breeding\n",
    "Lilacs out of the dead land, mixing\n",
    "Memory and desire, stirring\n",
    "Dull roots with spring rain.\n",
    "\"\"\"\n",
    "\n",
    "assert tokenize(wasteland, stop_words='is the of and') == \\\n",
    "    ['april','cruellest','month','breeding','lilacs','out','dead','land',\n",
    "     'mixing','memory','desire','stirring','dull','roots','with','spring',\n",
    "     'rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "Write a function `count_words` that takes a list of words and returns a dictionary where the keys in the dictionary are the unique words in the list and the values are the word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "checksum": "a94c1a7e986d4d8d3b80695b02e16015",
     "grade": false,
     "grade_id": "algorithmsex01b",
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "    \"\"\"Return a word count dictionary from the list of words in data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "77c9b760f563b041b6386781c42dc0e2",
     "grade": true,
     "grade_id": "algorithmsex01b",
     "points": 2
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'lines'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-71b7cc9f406e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this and the this from and a a a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m     \u001b[1;33m{\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'and'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'from'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'the'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'this'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-034065b48e22>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(s, stop_words, punctuation)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mempty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mempty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'lines'"
     ]
    }
   ],
   "source": [
    "assert count_words(tokenize('this and the this from and a a a')) == \\\n",
    "    {'a': 3, 'and': 2, 'from': 1, 'the': 1, 'this': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "Write a function `sort_word_counts` that return a list of sorted word counts:\n",
    "\n",
    "* Each element of the list should be a `(word, count)` tuple.\n",
    "* The list should be sorted by the word counts, with the higest counts coming first.\n",
    "* To perform this sort, look at using the `sorted` function with a custom `key` and `reverse`\n",
    "  argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "checksum": "5c68f353c6c5f3e1494e7d2902480ebf",
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a list of 2-tuples of (word, count), sorted by count descending.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"Return a list of 2-tuples of (word, count), sorted by count descending.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e3fd160136fc78f4a7c3fc027d445b4a",
     "grade": true,
     "grade_id": "algorithmsex01c",
     "points": 2
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort_word_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2b19d16a049a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0msort_word_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'this and a the this this and a a a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'this'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'and'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'the'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sort_word_counts' is not defined"
     ]
    }
   ],
   "source": [
    "assert sort_word_counts(count_words(tokenize('this and a the this this and a a a'))) == \\\n",
    "    [('a', 4), ('this', 3), ('and', 2), ('the', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "Perform a word count analysis on Chapter 1 of Moby Dick, whose text can be found in the file `mobydick_chapter1.txt`:\n",
    "\n",
    "* Read the file into a string.\n",
    "* Tokenize with stop words of `'the of and a to in is it that as'`.\n",
    "* Perform a word count, the sort and save the result in a variable named `swc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6cff4e8e53b15273846c3aecaea84a3d",
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0c74fa7fa2b9ad5a6b54a0b3f04ac9dc",
     "grade": true,
     "grade_id": "algorithmsex01d",
     "points": 2
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'swc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-79f30673d9f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mswc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m848\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'swc' is not defined"
     ]
    }
   ],
   "source": [
    "assert swc[0]==('i',43)\n",
    "assert len(swc)==848"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {}
   },
   "source": [
    "Create a \"Cleveland Style\" [dotplot](http://en.wikipedia.org/wiki/Dot_plot_%28statistics%29) of the counts of the top 50 words using Matplotlib. If you don't know what a dotplot is, you will have to do some research..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6cff4e8e53b15273846c3aecaea84a3d",
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "481908a47f48647c344ed328c691ba63",
     "grade": true,
     "grade_id": "algorithsex01e",
     "points": 2
    }
   },
   "outputs": [],
   "source": [
    "assert True # use this for grading the dotplot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
